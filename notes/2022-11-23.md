---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Classification of Text Data

## Next Week

Speakers:

- Monday (Zoom): [Justin White](https://www.linkedin.com/in/thejustinwhite)
- Wednesday (TBD): [Cass Wilkinson Saldana](https://datasparkri.org/our-people#:~:text=CASS%20WILKINSON%20SALDA%C3%91A%2C%20DATA%20ANALYST) from [DataSpark RI](https://datasparkri.org/) Me
- Friday (Zoom): [Milecia McGregor](https://www.linkedin.com/in/milecia) speaking on Deploying Models


```{code-cell} ipython3
from sklearn.feature_extraction import text
from sklearn.metrics.pairwise import euclidean_distances
from sklearn import datasets
import pandas as pd
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split

ng_X,ng_y = datasets.fetch_20newsgroups(categories =['comp.graphics','sci.crypt'],
                    return_X_y = True)
```

## News Data

Lables are the topic of the article 0 = computer graphics, 1 = cyrptography.
```{code-cell} ipython3
ng_y[:5]
```

the X is he actual text
```{code-cell} ipython3
ng_X[0]
```

##

We're going to instantiate the object and fit it two the whole dataset.
```{code-cell} ipython3
count_vec = text.CountVectorizer()
ng_vec = count_vec.fit_transform(ng_X)
```



```{important}
I changed the following a little bit from class so that we can use the same test/train split for the two different types of transformation so that we can compare them more easily.

This also helps illustrate when using the fit and transform separately is helpful.
```

```{code-cell} ipython3
ng_X_train, ng_X_test, ng_y_train, ng_y_test = train_test_split(
                                        ng_X, ng_y, random_state=0)
```

Now, we can use the transformation that we fit to the whole dataset to transform the train and test portions of the data separately.

The transform method also returns the sparse matrix directly so we no longer need the `toarray` method.

```{code-cell} ipython3
ng_vec_train = count_vec.transform(ng_X_train)
ng_vec_test = count_vec.transform(ng_X_test)
```

```{code-cell} ipython3
ng_vec_train[0]
```

```{code-cell} ipython3
clf = MultinomialNB()
```

```{code-cell} ipython3
clf.fit(ng_vec_train,ng_y_train).score(ng_vec_test,ng_y_test)
```


##


We wanted the TfidfVectorizer, not the transformer, so that it accepts documents not features. We will again, instantiate the object and then fit on the whole dataset.

```{code-cell} ipython3
tfidf = text.TfidfVectorizer()

tfidf.fit(ng_X)
```


We can see this works, because the code runs, but for completeness , we can also check the input again to compare with the above.

```{code-cell} ipython3
print('\n'.join(tfidf.fit.__doc__.split('\n')[:6]))
```

This now takes documents as we wanted. Since we split the data before transforming, we can then apply the new fit using the transform on the train/test splits.

```{code-cell} ipython3
ng_tfidf_train = tfidf.transform(ng_X_train)
ng_tfidf_test = tfidf.transform(ng_X_test)
```

Since these splits were made before we can use the same targets we used above.

```{code-cell} ipython3
clf.fit(ng_tfidf_train,ng_y_train).score(ng_tfidf_test,ng_y_test)
```

## Comparing representations

+++

To start, we will look at one element from each in order to compare them.

```{code-cell} ipython3
ng_tfidf_train[0]
```

```{code-cell} ipython3
ng_vec_train[0]
```

To start they both have 84 elements, since it is two different representations of the same document, that makes sense.  We can check a few others as well

```{code-cell} ipython3
ng_tfidf_train[1]
```

```{code-cell} ipython3
ng_vec_train[1]
```

```{code-cell} ipython3
(ng_vec_train[4]>0).sum() == (ng_tfidf_train[4]>0).sum()
```

Let's pick out a common word so that the calculation is meaningful and do the tfidf calucation. To find a common word in the dictionary, we'll first filter the vocabulary to keep only the words that occur at least 300 times in the training set. We sum along the columns of the matrix, transform it to an array, then iterate over the sum, enumerated (assigning the number to each element of the sum) and use that to get the word out, if its total is over 300.  I saw that this is actually a sort of long list, so I chose to only print out the first 25. We print them out with the index so we can use it for the one we choose.  

```{code-cell} ipython3
[(count_vec.get_feature_names()[i],i) for i, n in
         enumerate(np.asarray(ng_vec_train.sum(axis=0))[0])
 if n>300][:25]
```

Let's use computer.

```{code-cell} ipython3
computer_idx = 6786
count_vec.get_feature_names()[computer_idx]
```

```{code-cell} ipython3
ng_vec_train[:,computer_idx].toarray()[:10].T
```

```{code-cell} ipython3
ng_tfidf_train[:,computer_idx].toarray()[:10].T
```

So, we can see they have non zero elements in the same places, meaning that in both representations the column refers to the same thing.

We can compare the untransformed to the count vectorizer:

```{code-cell} ipython3
len(ng_X_train[0].split())
```

```{code-cell} ipython3
ng_vec_train[0].sum()
```

We see that it is just a count of the number of total words, not unique words, but total

```{code-cell} ipython3
ng_tfidf_train[0].sum()
```

The tf-idf matrix, however is normalized to make the sums smaller. Each row is not the same, but it is more similar.

```{code-cell} ipython3
sns.displot(ng_vec_train.sum(axis=1),bins=20)
```

```{code-cell} ipython3
sns.displot(ng_tfidf_train.sum(axis=1),bins=20)
```

We can see that the `tf-idf` makes the totals across documents more spread out.

+++

When we sum across words, we then get to see how

+++

From the documentation we see that the idf is not exactly the inverse of the number of documents, it's also rescaled some.

$$ idf = \log \frac{1 +n }{1 +df} + 1 $$

+++

In this implementation, each row is the normalized as well, to keep them small, so that documents of different sizes are more comparable.  For example, if we return to what we did last week. 
