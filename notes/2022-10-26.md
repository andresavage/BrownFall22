---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Interpretting Regression

```{code-cell} ipython3
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
sns.set_theme(font_scale=2,palette='colorblind')
```


## Multivariate Regression

We can also load data from Scikit learn.

This dataset includes 10 features measured on a given date and an measure of
diabetes disease progression measured one year later. The predictor we can train
with this data might be someting a doctor uses to calculate a patient's risk.  


```{code-cell} ipython3
# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)
X_train,X_test, y_train,y_test = train_test_split(diabetes_X, diabetes_y ,
                         test_size=20,random_state=0)
```

```{code-cell} ipython3
X_train.shape
```

```{code-cell} ipython3
regr_db = linear_model.LinearRegression()
```

```{code-cell} ipython3
regr_db.__dict__
```

We have an empty estimator object at this point and then we can fit it as usual.


```{code-cell} ipython3
regr_db.fit(X_train,y_train)
```

This model predicts what lab measure a patient will have one year in the future
based on lab measures in a given day.  Since we see that this is not a very high
r2, we can say that this is not a perfect predictor, but a Doctor, who better
understands the score would have to help interpret the core.


```{code-cell} ipython3
regr_db.__dict__
```
We can look at the estimator again and see what it learned. It describes the model like a line:

$$ \hat{y} = mx+b$$

except in this case it's multivariate, so we can write it like:

$$ \hat{y} = \beta^Tx + \beta_0 $$

where $\beta$ is the `regr_db.coef_` and $\beta_0$ is `regr_db.intercept_` and that's a vector multiplication and $\hat{y}$ is `y_pred` and $y$ is `y_test`.  

In scalar form it can be written like

$$ \hat{y} = \sum_{k=0}^d(x_k*\beta_k) + \beta_0$$

where there are $d$ features, that is $d$= `len(X_test[k])` and $k$ indexed into it. For example in the below $k=0$

```{code-cell} ipython3
X_test[0]
```

We can compute the prediction manually:
```{code-cell} ipython3
sum(regr_db.coef_*X_test[0])  + regr_db.intercept_
```

and see that it matches

```{code-cell} ipython3
regr_db.predict(X_test[:2])
```

```{code-cell} ipython3
regr_db.score(X_test,y_test)
```

We can also look at the residuals and see that they are fairly randomly spread out.

```{code-cell} ipython3
y_pred = regr_db.predict(X_test)
plt.scatter(y_test,y_pred)
plt.plot(y_pred,y_pred)
```


```{code-cell} ipython3

```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

## Questions After Class

### Is there a way to calculate p value in addition to r^2?

The $R^2$ is a measure of the quality of the regression fit, but a p-value is not.  A p-value implies a broader experimental framework, so it is not included in this object. `sklearn` does have tools that will calculate a p-value when appropriate, but it not built into this estimator object. The [`scipy.stats.linregress`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html) estimator does compute a p-value, and allows you to specify under which statistical test you want that p-value computed (two-sized, one-sided greater, or one-sided lesser).  

Broadly, p-values are very [frequently misinterpretted and misused](https://www.frontiersin.org/articles/10.3389/fphy.2016.00006/full).  Their use is not common in ML (because they're usually not the right thing) and being actively discouraged in other fields (eg psychology) in favor of more reliable and consistently well interpretted statistics.
