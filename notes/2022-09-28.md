---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Fixing Data representations


## Admin

- next assignment posted tonight.


### a4 TLDR:
- Review how your new dataset manipulation skills could have helped you in A2 or A3.
- clean provided (in the template) datasets
  - do tiny EDA to show complete;
  - add more EDA to get summarize and visualize
  - clean a specific dataset for access level 2 or python level 2 also; do both if you need all 3 achievments (prepare, access, python)
- Study some examples and notice patterns in data clearning

### Portfolio update

````{margin}
```{note}
The portfolio is open ended intentionally.  I want you to learn these skills a
little bit deeper than you have for the assignments, which is a little bit
deeper than we cover in class and show me that you learned.  I do *not* want you
to spend too much effort guessing what I want. I will look at what you submit
for evidence of learning and assess that.  There is not a single "right" answer.
```
````


- merge in your work from assignment 1
- portoflio will be due in ~2 weeks start planning
- read the [instructions](portfolioindex) and example [ideas](check1ideas); there will be time for q&a on Friday
- you can also create an outline and get feedback on your plan using an issue on your portflio repo


## Review Filtering

```{code-cell} ipython3
import pandas as pd
```

We can also filter using the `isin` method to compare each item in a column to a list

````{margin}
```{note}
You can see more about [groupby](groupby-detail) in notes from last week.
```
````


```{code-cell} ipython3
arabica_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/arabica_data_cleaned.csv'
# load the data
coffee_df = pd.read_csv(arabica_data_url)
# get total bags per country
bags_per_country_df = coffee_df.groupby('Country.of.Origin')['Number.of.Bags'].sum()

# sort descending, keep only the top 10 and pick out only the country names
top_bags_country_list = bags_per_country_df.sort_values(ascending=False)[:10].index

# filter the original data for only the countries in the top list
top_coffee_df = coffee_df[coffee_df['Country.of.Origin'].isin(top_bags_country_list)]
```


Yes this is a Series, not a data Frame, but a DataFrame is built of Series, so this is a small error in naming. `top_bags_country_list` is also an `Index` not a `list` but the names need to give an idea, not necessarily be precise so my choices are okay, but could be better.

```{code-cell} ipython3
type(coffee_df['Number.of.Bags'])
```

```{code-cell} ipython3
type(coffee_df.loc[1])
```

We can look at the final result
```{code-cell} ipython3
top_coffee_df.head()
```


```{code-cell} ipython3
top_coffee_df.shape, coffee_df.shape
```

## Fixing a Column

In tidy data each column is exactly one variable. Let's look at the `Bag.Weight`


```{code-cell} ipython3
coffee_df['Bag.Weight'].sample(10)
```

This is actually two pieces of information, the value measured and the units used.  In addition to the fact that there are multiple units, even if we could convert them, we cannot do math on these because they're strings. (notice it says "object" as the type)

Series have a `str` attribute so we can apply base python string methods to each value in a column.

```{code-cell} ipython3
coffee_df['Bag.Weight'].str
```

What we want is to split it
```{code-cell} ipython3
coffee_df['Bag.Weight'].str.split(' ').sample(10)
```

Since this looks good, we can save it to a variable.

```{code-cell} ipython3
split_bw = coffee_df['Bag.Weight'].str.split(' ')
```

We still have one problem, each element contains a list.

```{code-cell} ipython3
type(split_bw[0])
```

What we want is a `DataFrame` with two columns, one of the first value and one of the second value for each list.

A `DataFrame` is build of Series which are each row (and each column) the lists we have are each the content that we want to put in one Series and then stack them all together.  

To do this, we can cast each list to a `Series` using the `apply` method which automatically stacks Series or DataFrames back together after applying a function to each row (or column).

Recall that in python, we can use types as functions to cast
```{code-cell} ipython3
num = '2'
```

```{code-cell} ipython3
type(int(num))
```

```{code-cell} ipython3
type(num)
```

So, back to our real problem:



```{code-cell} ipython3
split_bw.apply(pd.Series)
```

This looks good, but these columns are not very informative, so we can rename them.

Rename can take many different inputs and be applied on lots of parts, but we will use it with a dictionary that serves as a mapping (like the mathematical sense of mapping; like a function).  It will change the column with each key to the value.

```{code-cell} ipython3
split_df = split_bw.apply(pd.Series).rename(columns={0:'Weight',1:'Units'})
split_df
```

This is good, but it's only the one column.  We can use concat to put them together.

```{code-cell} ipython3
pd.concat([coffee_df,split_df],axis=1).head(2)
```

Why `axis=1` again?  

Let's look at the other one.
```{code-cell} ipython3
bad_concat = pd.concat([coffee_df,split_df],axis=0)
bad_concat.shape
```
It has double the rows
```{important}
checking the shape is the first thing to do to see if you did the right one
```

and the bottom of it most columns are NaN (null, missing)
```{code-cell} ipython3
bad_concat.tail()
```


(unpacking-jsons)=
## Unpacking Jsons

```{code-cell} ipython3
rhodyprog4ds_gh_events_url = 'https://api.github.com/orgs/rhodyprog4ds/events'
```

```{code-cell} ipython3
course_gh_df = pd.read_json(rhodyprog4ds_gh_events_url)
course_gh_df.head()
```
We want to transform each one of those from a dictionary like thing into a
row in a data frame.

```{code-cell} ipython3
type(course_gh_df['actor'])
```

Recall, that base python types can be used as function, to cast an object from
type to another.
```{code-cell} ipython3
5
```

```{code-cell} ipython3
type(5)
```

```{code-cell} ipython3
str(5)
```

To unpack one column we can cast each element of the column to a series and then stack them back together.

First, let's look at one row of one column
```{code-cell} ipython3
course_gh_df['actor'][0]
```

Now let's cast it to a Series
```{code-cell} ipython3
pd.Series(course_gh_df['actor'][0])
```

What we want is to do this over and over and stack them.

 The `apply` method does this for us, in one compact step.  

```{code-cell} ipython3
course_gh_df['actor'].apply(pd.Series)
```

How can we do this for all of the columns and put them back together after?

First, let's make a list of the columns we need to convert.
```{code-cell} ipython3
js_cols = ['actor','repo','payload','org']
```

When we use `.apply(pd.Series)` we get a a DataFrame.

```{code-cell} ipython3
type(course_gh_df['actor'].apply(pd.Series))
```

`pd.concat` takes a list of DataFrames and puts the together in one DataFrame.

to illustrate, it's nice to make small dataFrames.

```{code-cell} ipython3
df1 = pd.DataFrame([[1,2,3],[3,4,7]], columns = ['A','B','t'])
df2 = pd.DataFrame([[10,20,30],[30,40,70]], columns = ['AA','BB','t'])
df1
```

```{code-cell} ipython3
df2
```

If we use concat with the default settings, it stacks them vertically and aligns any columns that have the same name.  

```{code-cell} ipython3
pd.concat([df1,df2])
```
So, since the original DataFrames were both 2 rows with 3 columns each, with one column name appearing in both, we end up with a new DataFrame with shape (4,5) and it fills with `NaN` in the top right and the bottom left.

```{code-cell} ipython3
pd.concat([df1,df2]).shape
```

We can use the `axis` parameter to tell it how to combine them. The default is `axis=0`, but `axis=1` will combine along rows.
```{code-cell} ipython3
pd.concat([df1,df2], axis =1)
```

So now we get no NaN values, because both DataFrames have the same number of rows and the same index.

```{code-cell} ipython3
df1.index == df2.index
```

and we have a total of 6 columns and 2 rows.

```{code-cell} ipython3
pd.concat([df1,df2], axis =1).shape
```

Back to our gh data, we want to make a list of DataFrames where each DataFrame corresponds to one of the columns in the original DataFrame, but unpacked and then stack them horizontally (`axis=1`) because each DataFrame in the list is based on the same original DataFrame, they again have the same index.
```{code-cell} ipython3
pd.concat([course_gh_df[cur_col].apply(pd.Series) for cur_col in js_cols],
         axis=1)
```

```{admonition} Try it Yourself
examine the list of DataFrames to see what structure they share and do not share
```

In this case we get the same 30 rows, beacuse that's what the API gave us and turned our 4 columns from `js_cols` into 26 columns.
```{code-cell} ipython3
pd.concat([course_gh_df[cur_col].apply(pd.Series) for cur_col in js_cols],
         axis=1).shape
```

If we had used the default, we'd end up with 120 rows (30*4) and we have only 19 columns, because there are subfield names that are shared across the original columns. (eg most have an `id`)
````{margin}
```{admonition} Try it yourself
How could you anticipate how many are shared?
```
````

```{code-cell} ipython3
pd.concat([course_gh_df[cur_col].apply(pd.Series) for cur_col in js_cols],
         axis=0).shape
```

we might want to rename the new columns so that they have the original column
name prepended to the new name. This will help us distinguish between the different `id` columns

pandas has a `rename` method for this.

and this is another job for lambdas.
```{code-cell} ipython3
pd.concat([course_gh_df[cur_col].apply(pd.Series).rename(columns = lambda c: cur_col + '_' +c)
           for cur_col in js_cols],
         axis=1)
```

the `rename` method's `column` parameter can take a lambda defined inline, which is helpful, because we want that function to take one parameter (the current columnt name) and do the same thing to all of the columns within a single DataFrame, but to prepend a different thing for each DataFrame

```{code-cell} ipython3

pd.concat([course_gh_df[cur_col].apply(pd.Series).rename(columns = lambda c: cur_col + '_' +c)
           for cur_col in js_cols],
         axis=1)
```

So now, we have the unpacked columns with good column names, but we lost the columns that were originally good.


How can we append the new columns to the old ones?
First we can make a DataFrame that's just the columns not on the list that we're goign to expand.
```{code-cell} ipython3
course_gf_df_good = course_gh_df[[col for col in
          course_gh_df.columns if not(col in js_cols)]]
course_gf_df_good
```

Then we can prepend that to the list that we pass to `concat`. We have to put it in a list first, then use + to do that.
```{code-cell} ipython3
pd.concat([course_gf_df_good]+[course_gh_df[col].apply(pd.Series,).rename(
  columns= lambda i_col: col + '_' + i_col )
      for col in js_cols],axis=1)
```
