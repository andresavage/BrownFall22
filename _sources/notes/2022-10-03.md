---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Building Datasets from Multiple Sources

focus this week is on how to programmatically combine sources of data

We will start by looking at combining multiple tabular data formats and see how to get data from other sources.  



## Self- assessment, what's your plan

Take a few minutes to think about the following questions and make a few notes
for yourself whereever you need them to be (a planner, calendar, etc).
Share one takeaway or question you have below when you're done.

1. What achievements have you earned?
1. Does BrightSpace seem accurate to what you've done?
1. If not, e-mail brownsarahm with [CSC310] or [DSP310] in the subject and specific details about what you think is missing and why
1. Are you on track to earn the grade you want in this class?
1. If not, what will you need to do (respond more in class, submit more
   assignments, use your portfolio to catch up) to get back on track?
1. If you are on track and you want to earn above a B, take a minute to think
about your portfolio. (tip: post an idea as an issue to get early feedback and help shaping your idea)

## Logistics

Check your earned achievements. See the [instructions](gradecheck) that are now saved for future reference on the left side.


## Merges

```{code-cell} ipython3
import pandas as pd
```

I created a folder with [datasets we use in class](https://github.com/rhodyprog4ds/rhodyds/tree/main/data)

```{code-cell} ipython3
course_data_url = 'https://raw.githubusercontent.com/rhodyprog4ds/rhodyds/main/data/'
```

 We can load in two data sets of player information.

```{code-cell} ipython3
df_18 = pd.read_csv(course_data_url+ '2018-players.csv')
df_19 = pd.read_csv(course_data_url+ '2019-players.csv')
```

and take a peek at each

```{code-cell} ipython3
df_18.head(2)
```

```{important}
Remember `columns` is an attribute, so it does not need `()`
```

```{code-cell} ipython3
df_19.columns
```

Let's make note of the shape of each

```{code-cell} ipython3
df_18.shape, df_19.shape
```

## What if we want to analyze them together?

We can combine them vertically:

```{code-cell} ipython3
pd.concat([df_18,df_19]).shape
```

Note that this has the maximum number of columns (because both had some overlapping
  columns) and the total number of rows.


## How can we find which players changed teams?

To do this we want to have one player column and a column with each year's team.

We can use a merge to do that.

````{margin}
```{note}
the `head` here is only to help us see more at a time
```
````

```{code-cell} ipython3
pd.merge(df_18,df_19,).head(2)
```

if we merge them without any parameters, it tries to merge on all shared columns.  We want to merge them using the `PLAYER_ID` column though, we would say hat we are "merging on player ID" and we use the `on` parameter to do it

```{code-cell} ipython3
pd.merge(df_18,df_19, on = 'PLAYER_ID').head(2)
```

Since there are other columns that appear in both DataFrames, they get a suffis, which by default is `x` or `y`, we can specify them though.

```{code-cell} ipython3
pd.merge(df_18,df_19, on = 'PLAYER_ID',
        suffixes=('_2018','_2019')).head(2)
```

We also told it what to append to any column names that match, but are not the same across both datasets.

```{code-cell} ipython3
df_18.head(1)
```

```{code-cell} ipython3
df_19.head(1)
```

```{code-cell} ipython3
df1819 = pd.merge(df_18,df_19, on = 'PLAYER_ID',
        suffixes=('_2018','_2019'))
```

```{code-cell} ipython3
df1819.shape
```

By default, this uses an *inner* merge, so we get the players that are in both datasets only.

```{code-cell} ipython3
df1819.head()
```

Some players still appear twice, because they were in one of the datsets twice, this
happens when a player plays for two team in one season.

## Which players played in 2018, but not 2019?

We have different types of merges, inner is both, out is either.  Left and right keep all the rows of one dataFrame.  We can use left with `df_18` as the left DataFrame to see which players played only in 18.

```{code-cell} ipython3
pd.merge(df_18,df_19,on='PLAYER_ID', how='left',suffixes=('_2018','_2019')).tail()
```

To pick out those rows:

```{code-cell} ipython3
df_18_only = pd.merge(df_18,df_19,on='PLAYER_ID', how='left', suffixes=('_2018','_2019'))
df_18_only[df_18_only['SEASON_2019'].isna()]
```

```{code-cell} ipython3
df_18_left = pd.merge(df_18,df_19.drop(columns=['SEASON'])
                                       ,on='PLAYER_ID', how='left', suffixes=('_2018','_2019'))
df_18_only = df_18_only[df_18_only['TEAM_ID_2019'].isna()]
df_18_only.head()
```

```{code-cell} ipython3
n_18_only, _ = df_18_only.drop_duplicates(subset=['PLAYER_ID']).shape
n_18_only
```

## Which players played for the same team both seasons?

```{code-cell} ipython3
df_same_team = pd.merge(df_18,df_19, on = ['PLAYER_ID','TEAM_ID'],)
df_same_team.head()
```

In this case, the suffix only applies to season, but they're not telling us much, so we can clean it up using `drop` before we merge.

```{code-cell} ipython3
df_18_only_clean = pd.merge(df_18.drop(columns='SEASON'),df_19.drop(columns='SEASON'), on = ['PLAYER_ID','TEAM_ID'],)
df_18_only_clean.head()
```

```{code-cell} ipython3
df_18_only_clean.shape
```

```{code-cell} ipython3
df_18_only_clean.drop_duplicates(subset=['PLAYER_ID']).shape
```

We do not need to drop the duplicates in this case becaue we merged on two columns and there were no actual duplicates in the original dataset.

+++

## Visualizing merges

```{code-cell} ipython3
left = pd.DataFrame(
    {
        "key": ["K0", "K1", "K2", "K4"],
        "A": ["A0", "A1", "A2", "A4"],
        "B": ["B0", "B1", "B2", "B4"],
    }
)


right = pd.DataFrame(
    {
        "key": ["K0", "K1", "K2", "K3"],
        "C": ["C0", "C1", "C2", "C3"],
        "D": ["D0", "D1", "D2", "D3"],
    }
)
```

```{code-cell} ipython3
left
```

```{code-cell} ipython3
right
```

```{code-cell} ipython3
pd.merge(left, right, how='inner',)
```

```{code-cell} ipython3
pd.merge(left, right, how='outer')
```

```{code-cell} ipython3
pd.merge(left, right, how='left')
```

```{code-cell} ipython3
pd.merge(left, right, how='right')
```

 We can merge on multiple columns too/

```{code-cell} ipython3
left = pd.DataFrame(
    {
        "key1": ["K0", "K0", "K1", "K2"],
        "key2": ["K0", "K1", "K0", "K1"],
        "A": ["A0", "A1", "A2", "A3"],
        "B": ["B0", "B1", "B2", "B3"],
    }
)


right = pd.DataFrame(
    {
        "key1": ["K0", "K1", "K1", "K2"],
        "key2": ["K0", "K0", "K0", "K0"],
        "C": ["C0", "C1", "C2", "C3"],
        "D": ["D0", "D1", "D2", "D3"],
    }
)
```

```{code-cell} ipython3
left
```

```{code-cell} ipython3
right
```

```{code-cell} ipython3
pd.merge(left, right, on=["key1", "key2"])
```

```{code-cell} ipython3
pd.merge(left, right, on=["key1", "key2"],how='outer')
```

```{code-cell} ipython3
pd.merge(left, right,on = 'key1' )
```

```{code-cell} ipython3

```

```{code-cell} ipython3
left = pd.DataFrame({"A": [1, 2], "B": [2, 2]})

right = pd.DataFrame({"A": [4, 5, 6], "B": [2, 2, 2]})

```

```{code-cell} ipython3
left
```

```{code-cell} ipython3
right
```

```{code-cell} ipython3
pd.merge(left, right, on="B", how="outer")
```

```{code-cell} ipython3

```

## Questions After Class

```{important}
several questions were easiest to answer within the narrative of the notes above.
```

### How do I represent NaN as a variable? (Ex. df1819['TEAM_ID_y'==NaN]...something like that?)

For that specific case, you can use the `isna` method as I did above, but if you need a NaN constant otherwise pandas provides

```{code-cell} ipython3
pd.NA
```

and numpy provides
```{code-cell} ipython3
import numpy as np
np.nan
```


Watch out though because they are not the same:

```{code-cell} ipython3
np.nan == pd.NA
```

and this cannot even assert


```{code-cell} ipython3
assert pd.NA == np.nan
```

The `pandas` `pd.isna` method is robust, and it knows how `numpy` works (because it is built on top and imports).


```{code-cell} ipython3
pd.isna(np.nan)
```

```{code-cell} ipython3
pd.isna(pd.NA)
```


However, `numpy` does not know `pandas`

```{code-cell} ipython3
np.isnan(pd.NA)
```
and returns a value that cannot be used for indexing

### Is there an easier way to look at the changes with merge?

Any of the tools we have to look at a DataFrame will work.  I think using a small DataFrame is the best way to get a good idea of how they each work, so I included that.  Overall, checking the shape gives a broad view and then comparing values gives the detials.

### Do merges also delete any other overlapping columns other than the one they are told to consolidate on?

No they copy them all

### in pd.merge(p18,p19, on='PLAYER_ID',how='____').shape is p18 and p19 supposed to be df_18 and df_19?

Yes, sorry, I read them in using different names than were in my notes

### Learning more about accessing data from databases

We will access databases on Wednesday

### How to merge data that does not line up as well as these two datasets?

We will see how to merge on columns that have the same data, but different columns this week. When there is no columns that match value to value, you have to transform and add new columns, combining what we learned about cleaning data to make them line up somehow.  For example, maybe one dataset has dates like `YYYY-MM-DD` and the other data set has only months like "January". You could split the whole date into three columns and transform the strings to numbers or numbers to strings by treating the columns as [dates](https://pandas.pydata.org/docs/user_guide/timeseries.html)

### Why did we merged on 'PLAYER_ID'?

We were interested in linking based on the players.


### What is the second best source after documentation? For ex: you found a parameter that might do what you want it to in pandas, but where do you go after to make sure? I'm not sure if I ran it, I'd specifically know if it "worked"

Ideally, you should know what you are looking for to know if it worked or not.  If you are not sure what you are looking for, that is a good time to try to think that through, or attend office hours.  Next is to create an issue on your assignment repo if the question might reveal a solution.


### I think I need to understand how GitHub works because I'm following the steps of the assignments and I feel like I'm doing something wrong every time I have to work on GitHub.

If you are getting feedback, you are close enough.  However, I am offering an extra session on GitHub on Friday.
