---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# Web Scraping

```{code-cell} ipython3
import requests
from bs4 import BeautifulSoup
import pandas as pd
```

````{warning}
If it says it cannot load one of the libraries, use pip inside your notebook to install, then restart your kernel (Kernel menu, choose restart)

```
pip install beautifulsoup4
```
````


We have that `read_html` can get content from an actual website, not a data file that is hosted somewhere on the internet, that takes tables on a website and returns a list of DataFrames.

## Everything is Data

For the purpose of this class, it is best to think of the content on a web page like a datastructure.  

![html anatomy](https://cdn2.hubspot.net/hub/53/file-1519188549-jpg/blog-files/webpage-setup.jpg)


![HTML tree structure](http://www.w3schools.com/js/pic_htmltree.gif)

there are tags `<>` that define the structure, and these can be further classified with `classes`

## Scraping a URI website


We're going to create a DataFrame about URI CS & Statistics Faculty.

from the [people page](https://web.uri.edu/cs/people/) of the department website.


We can inspect the page to check that it's well structured

```{warning}
With great power comes great responsibility.

- always check the [robots.txt](https://web.uri.edu/robots.txt)
- do not do things that the owner says not to do
- government websites are typically safe
```

We'lls ave the URL for easy use
```{code-cell} ipython3
cs_people_url = 'https://web.uri.edu/cs/people/'
```

Then we can use the `requests` library to make a call to the internet.  It actually gets back a [response object](https://requests.readthedocs.io/en/latest/api/#requests.Response) which has a lot of extra information.  For today we only need the `content` from the page which is an attrtibute of that object
```{code-cell} ipython3
cs_people_html = requests.get(cs_people_url).content
```

This is raw:
```{code-cell} ipython3
type(cs_people_html)
```

```{code-cell} ipython3
cs_people_html
```

But we do not need to manually write search tools, that's what [`BeautifulSoup`](https://beautiful-soup-4.readthedocs.io/en/latest/) is for.

```{code-cell} ipython3
cs_people = BeautifulSoup(cs_people_html,'html.parser')
```

In this object we can use any tag from the file and get back the first instance
```{code-cell} ipython3
cs_people.a
```

```{code-cell} ipython3
cs_people.h3
```

More helpful is the `find_all` method we wnat to find all `div` tags that are "peopleitem" class. We decided this by inspecting the code on the website.
```{code-cell} ipython3
cs_people.find_all("div","peopleitem")
```

this is a long, object and we can see it looks iterable (`[` at the start)

```{important}
answer to questions about searching [from the docs](https://beautiful-soup-4.readthedocs.io/en/latest/index.html?highlight=find_all#the-keyword-arguments)
```

We could search all tags for the class attribute like this:
```{code-cell} ipython3
cs_people.find_all(class="peopleitem")[0]
```

We can also look at only the first instance
```{code-cell} ipython3
cs_people.find_all("peopleitem")[0]
```

We notice that the name is inside a `<h3>` tag with class `p-name` and then inside an a tag after that.  We also know from looking at the overall page that there are lots of other a tags, so we do not want to search all of those.
```{code-cell} ipython3
names = [n.a.string for n in cs_people.find_all("h3","p-name")]
names
```

How to pull out the titles for each person (eg Assitatn Teaching Professor, Associate Professor)

```{code-cell} ipython3
titles = [t.string for t in cs_people.find_all("p","people-title")]
```

```{code-cell} ipython3
titles
```

We can pull out two more things, the people-department indicates who is CS & who is Statistics.
```{code-cell} ipython3
disciplines = [d.string for d in cs_people.find_all("p",'people-department')]
emails = [e.string for e in cs_people.find_all("a",'u-email')]
```

```{code-cell} ipython3
css_fac_df = pd.DataFrame({'name':names, 'title':titles,'e-mails':emails, 'discipline':disciplines})
css_fac_df
```


```{admonition}

think ahead: how could we add people's office numbers to the datagrame that we
just made?

*hint* my office is listed on [the page linked to my name](https://web.uri.edu/cs/meet/sarah-brown/)
```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

### Do you have any recommendations for learning html/css for the purpose of webscraping?

For webscraping only, careful examination of the page for patterns will be mostly enough. Rely on the nesting that the inspect or an IDE does. The following simple facts about website design will mostly be enough:
- tags are written like `<tagname>`
- classes are used to group similar tags and written like `class = list of classes separated by spaces`
- ids are used to "name" specific instances of tags like `id=section-qa`
- the other values inside tags are called attributes (class, id, href are attributes)
- the `<a>` tag is for links and it written like `<a href="url">link text</a>`

I will look for some examples, though.

## Is there a way to search just one person with that method?

We definitely can after pulling all the names, but the scraping is really for pulling the structure and reformatting batches of information more than finding a single thing. For finding one thing, there are better tools.

### what all the little commands in the inspection of a website are for?

### How do you know what to use to iterate through values in the HTML?

I knew I wanted the to look at each person, that was the information I wanted from the page, from visual inspection.  Then I inspected on one of the boxes about a person and noticed that they were a `div` tag with `peopleitem` class.  I actually decided just the way we did it in class.  

In the card for one person, I found each piece of information I wanted and then looked for the closest tag.  I also tried things that did not work before class to work out an example that would work, but whe you are learning new things, that is how it works.  Letting the computer tell you that you made a mistake is totally fine! Try things and experiment. Errors are okay.  

### How to use the find_all feature for just the class name?
use it as a keyword parameter like `class=`

### Can we get more practice webscraping and using the .find_all() function?

Try pulling additional information from this page (like the webpage for each person) and the information from that page.

### Will making a DataFrame via web scraping be use the DataFrame constructor, or is there more to it?

Use the constructor !
