---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Learning Curves

```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster

from sklearn import naive_bayes
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
sns.set_theme(palette='colorblind')
```

```{code-cell} ipython3
digits = datasets.load_digits()
```

```{code-cell} ipython3
type(digits)
```

```{code-cell} ipython3
digits
```

```{code-cell} ipython3
print(digits['DESCR'])
```

```{code-cell} ipython3
plt.gray()
plt.matshow(digits.images[9])
```

```{code-cell} ipython3
digits_X = digits.data
digits_y = digits.target
```

```{code-cell} ipython3
digits_X.shape, digits_y.shape
```

```{code-cell} ipython3
1797*8*8
```

```{code-cell} ipython3
svm_clf = svm.SVC(gamma=0.001)
gnb_clf = naive_bayes.GaussianNB()
```

```{code-cell} ipython3
# Cross validation with 100 iterations to get smoother mean test and train
# score curves, each time with 20% data randomly selected as a validation set.
cv = model_selection.ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)
```

```{code-cell} ipython3
train_sizes = np.linspace(.05,1,10)

train_sizes_svm, train_scores_svm, test_scores_svm, fit_times_svm, score_times_svm = model_selection.learning_curve(
    svm_clf,
    digits_X,
    digits_y,
    cv=cv,
    train_sizes=train_sizes,
    return_times=True,)
```

```{code-cell} ipython3
svm_learning_df = pd.DataFrame(data = train_sizes_svm, columns = ['train_size'])
# svm_learning_df['train_size'] = train_sizes_svm
svm_learning_df['train_score'] = np.mean(train_scores_svm,axis=1)
svm_learning_df['test_score'] = np.mean(test_scores_svm,axis=1)
svm_learning_df['fit_time'] = np.mean(fit_times_svm,axis=1)
svm_learning_df['score_times'] = np.mean(score_times_svm,axis=1)
```

```{code-cell} ipython3
svm_learning_df.head()
```

```{code-cell} ipython3
svm_learning_df_scores = svm_learning_df.melt(id_vars=['train_size'],
                                                value_vars=['train_score','test_score'])
svm_learning_df_scores.head(2)
```

```{code-cell} ipython3
sns.lineplot(data=svm_learning_df_scores,x='train_size',y='value',hue='variable')
```

```{code-cell} ipython3
train_sizes_gnb, train_scores_gnb, test_scores_gnb, fit_times_gnb, score_times_gnb = model_selection.learning_curve(
  gnb_clf,
  digits_X,
  digits_y,
  cv=cv,
  train_sizes=train_sizes,
  return_times=True,)
```

```{code-cell} ipython3
gnb_learning_df = pd.DataFrame(data = train_sizes_gnb, columns = ['train_size'])
# gnb_learning_df['train_size'] = train_sizes_gnb
gnb_learning_df['train_score'] = np.mean(train_scores_gnb,axis=1)
gnb_learning_df['test_score'] = np.mean(test_scores_gnb,axis=1)
gnb_learning_df['fit_time'] = np.mean(fit_times_gnb,axis=1)
gnb_learning_df['score_times_gnb'] = np.mean(score_times_gnb,axis=1)
```

```{code-cell} ipython3
gnb_learning_scores = gnb_learning_df.melt(id_vars=['train_size'],value_vars=['train_score','test_score'])
sns.lineplot(data = gnb_learning_scores, x ='train_size', y='value',hue='variable')
```

```{code-cell} ipython3

```

```{code-cell} ipython3

```

## Questions After Class

how do I run this? gh issue list --state all -L 45 --json title,url,state > grade-tracker.json

• Is fit time as important as accuracy? I would think generally for real life application we would want results over time.

• Why in the SVC model you used gamma=0.001 and not othe values? Why does that parameter represent in the model?

• I'm sure it will be in the notes but a better understanding of how learning curve works

• Can you go over the melt function again?

• running code will be posted tonight correct?

• nothing at the moment
